{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4e7dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Grammar Classifier\\saved_model-20220510T081104Z-001\\saved_model\\BERT\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "output_dir = 'E:\\Grammar Classifier\\saved_model-20220510T081104Z-001\\saved_model\\BERT'\n",
    "\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd5e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\manan\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torch-1.11.0-cp38-cp38-win_amd64.whl (158.0 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\manan\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d941b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b273c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3477d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test=pd.read_csv('E:\\Grammar Classifier\\saved_model-20220510T081104Z-001\\saved_model\\BERT\\\\review_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152b71eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          1\n",
       "star          0\n",
       "app_id        0\n",
       "reviewDate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dfe6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73b78ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          Anathi Khanyile\n",
       "1        Tony bahut funny hai Hill climbing racing my f...\n",
       "2                                                  Teturwu\n",
       "3        Hoooooooooooyaaaaaaaaa what a game hoooooooooo...\n",
       "4                                        This game is nice\n",
       "                               ...                        \n",
       "29995                                   Plz my Vidos viral\n",
       "29996                                                 Nice\n",
       "29997                    Disturbing too much as YouTube ad\n",
       "29998                                        Koub valo vai\n",
       "29999                            I want to grow my account\n",
       "Name: text, Length: 29999, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=test.text\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4f3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Manan\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions=[]\n",
    "\n",
    "for n in range(0,30):\n",
    "    input_ids=[]\n",
    "    attention_masks=[]\n",
    "    for sent in sentences[n*1000:(n+1)*1000]:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                                  sent,                      # Sentence to encode.\n",
    "                                  add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  max_length = 64,           # Pad & truncate all sentences.\n",
    "                                  pad_to_max_length = True,\n",
    "                                  return_attention_mask = True,   # Construct attn. masks.\n",
    "                                  return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                            )\n",
    "\n",
    "              # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "              # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "                # Forward pass, calculate logit predictions\n",
    "            outputs = model_loaded(input_ids, token_type_ids=None, \n",
    "                              attention_mask=attention_masks)  \n",
    "    logits = outputs[0]\n",
    "\n",
    "    for logit in logits:\n",
    "        index = logit.argmax()\n",
    "        if index == 1:\n",
    "            predictions.append(\"Gramatically correct\")\n",
    "        else:\n",
    "            predictions.append(\"Gramatically in-correct\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fd247e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc9cebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.concat([test,predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9372e9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'star', 'app_id', 'reviewDate', 0], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e40b93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e42ac5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f6a73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>star</th>\n",
       "      <th>app_id</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anathi Khanyile</td>\n",
       "      <td>5.0</td>\n",
       "      <td>com.fingersoft.hillclimb</td>\n",
       "      <td>18/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tony bahut funny hai Hill climbing racing my f...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>com.fingersoft.hillclimb</td>\n",
       "      <td>18/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teturwu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>com.fingersoft.hillclimb</td>\n",
       "      <td>18/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hoooooooooooyaaaaaaaaa what a game hoooooooooo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>com.fingersoft.hillclimb</td>\n",
       "      <td>18/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This game is nice</td>\n",
       "      <td>5.0</td>\n",
       "      <td>com.fingersoft.hillclimb</td>\n",
       "      <td>18/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>Plz my Vidos viral</td>\n",
       "      <td>5.0</td>\n",
       "      <td>video.like</td>\n",
       "      <td>21/03/21</td>\n",
       "      <td>Gramatically in-correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Nice</td>\n",
       "      <td>5.0</td>\n",
       "      <td>video.like</td>\n",
       "      <td>21/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Disturbing too much as YouTube ad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>video.like</td>\n",
       "      <td>21/03/21</td>\n",
       "      <td>Gramatically in-correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Koub valo vai</td>\n",
       "      <td>5.0</td>\n",
       "      <td>video.like</td>\n",
       "      <td>21/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>I want to grow my account</td>\n",
       "      <td>5.0</td>\n",
       "      <td>video.like</td>\n",
       "      <td>21/03/21</td>\n",
       "      <td>Gramatically correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29999 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  star  \\\n",
       "0                                        Anathi Khanyile   5.0   \n",
       "1      Tony bahut funny hai Hill climbing racing my f...   5.0   \n",
       "2                                                Teturwu   1.0   \n",
       "3      Hoooooooooooyaaaaaaaaa what a game hoooooooooo...   5.0   \n",
       "4                                      This game is nice   5.0   \n",
       "...                                                  ...   ...   \n",
       "29994                                 Plz my Vidos viral   5.0   \n",
       "29995                                               Nice   5.0   \n",
       "29996                  Disturbing too much as YouTube ad   1.0   \n",
       "29997                                      Koub valo vai   5.0   \n",
       "29998                          I want to grow my account   5.0   \n",
       "\n",
       "                         app_id reviewDate                    label  \n",
       "0      com.fingersoft.hillclimb   18/03/21     Gramatically correct  \n",
       "1      com.fingersoft.hillclimb   18/03/21     Gramatically correct  \n",
       "2      com.fingersoft.hillclimb   18/03/21     Gramatically correct  \n",
       "3      com.fingersoft.hillclimb   18/03/21     Gramatically correct  \n",
       "4      com.fingersoft.hillclimb   18/03/21     Gramatically correct  \n",
       "...                         ...        ...                      ...  \n",
       "29994                video.like   21/03/21  Gramatically in-correct  \n",
       "29995                video.like   21/03/21     Gramatically correct  \n",
       "29996                video.like   21/03/21  Gramatically in-correct  \n",
       "29997                video.like   21/03/21     Gramatically correct  \n",
       "29998                video.like   21/03/21     Gramatically correct  \n",
       "\n",
       "[29999 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "727260b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d7bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
